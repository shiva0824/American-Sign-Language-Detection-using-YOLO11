{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BGZofxfhM-KD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers, models, optimizers, regularizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.preprocessing import image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Downloading YOLO dataset from roboflow"
      ],
      "metadata": {
        "id": "f3Tpuu3ODyWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q roboflow\n",
        "from google.colab import userdata\n",
        "from roboflow import Roboflow\n",
        "\n",
        "rf = Roboflow(api_key=\"IVbw8GePPFfYhH9xk6mu\")\n",
        "project = rf.workspace(\"majorproject-25tao\").project(\"american-sign-language-v36cz\")\n",
        "version = project.version(2)\n",
        "dataset = version.download(\"yolov11\", location='dataset')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIYb9FANNTEe",
        "outputId": "4d4f982c-e554-40d2-e292-0a6be1226d3c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/80.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in dataset to yolov11:: 100%|██████████| 462106/462106 [00:24<00:00, 19205.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to dataset in yolov11:: 100%|██████████| 40560/40560 [00:08<00:00, 4656.34it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#YOLO to CNN conversion"
      ],
      "metadata": {
        "id": "_Nr1a55gD2dX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = [\n",
        "    \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\",\n",
        "    \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\", \"additional\", \"alcohol\", \"allergy\",\n",
        "    \"bacon\", \"bag\", \"barbecue\", \"bill\", \"biscuit\", \"bitter\", \"bread\", \"burger\", \"bye\",\n",
        "    \"cake\", \"cash\", \"cheese\", \"chicken\", \"coke\", \"cold\", \"cost\", \"coupon\", \"credit card\",\n",
        "    \"cup\", \"dessert\", \"drink\", \"drive\", \"eat\", \"eggs\", \"enjoy\", \"fork\", \"french fries\",\n",
        "    \"fresh\", \"hello\", \"hot\", \"icecream\", \"ingredients\", \"juicy\", \"ketchup\", \"lactose\",\n",
        "    \"lettuce\", \"lid\", \"manager\", \"menu\", \"milk\", \"mustard\", \"napkin\", \"no\", \"order\",\n",
        "    \"pepper\", \"pickle\", \"pizza\", \"please\", \"ready\", \"receipt\", \"refill\", \"repeat\", \"safe\",\n",
        "    \"salt\", \"sandwich\", \"sauce\", \"small\", \"soda\", \"sorry\", \"spicy\", \"spoon\", \"straw\",\n",
        "    \"sugar\", \"sweet\", \"thank-you\", \"tissues\", \"tomato\", \"total\", \"urgent\", \"vegetables\",\n",
        "    \"wait\", \"warm\", \"water\", \"what\", \"would\", \"yoghurt\", \"your\"\n",
        "]"
      ],
      "metadata": {
        "id": "4EVcionfNVRY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def yolo_to_cnn_format(yolo_annotation, img_width, img_height):\n",
        "    class_id, x_center, y_center, width, height = map(float, yolo_annotation)\n",
        "    x_center, y_center, width, height = (\n",
        "        x_center * img_width,\n",
        "        y_center * img_height,\n",
        "        width * img_width,\n",
        "        height * img_height,\n",
        "    )\n",
        "    x_min = int(x_center - width / 2)\n",
        "    y_min = int(y_center - height / 2)\n",
        "    x_max = int(x_center + width / 2)\n",
        "    y_max = int(y_center + height / 2)\n",
        "    return int(class_id), x_min, y_min, x_max, y_max\n",
        "\n",
        "def convert_dataset(images_dir, labels_dir, output_dir, class_names, target_size=(255, 255)):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    for label_file in os.listdir(labels_dir):\n",
        "        img_file = label_file.replace('.txt', '.jpg')\n",
        "        img_path = os.path.join(images_dir, img_file)\n",
        "        label_path = os.path.join(labels_dir, label_file)\n",
        "\n",
        "        if not os.path.exists(img_path):\n",
        "            print(f\"Image file {img_path} not found, skipping.\")\n",
        "            continue\n",
        "\n",
        "        img = cv2.imread(img_path)\n",
        "        img_height, img_width, _ = img.shape\n",
        "\n",
        "        with open(label_path, 'r') as f:\n",
        "            for line in f.readlines():\n",
        "                class_id, x_min, y_min, x_max, y_max = yolo_to_cnn_format(\n",
        "                    line.strip().split(), img_width, img_height\n",
        "                )\n",
        "\n",
        "                class_name = class_names[class_id]\n",
        "                class_dir = os.path.join(output_dir, class_name)\n",
        "                os.makedirs(class_dir, exist_ok=True)\n",
        "\n",
        "                cropped_img = img[y_min:y_max, x_min:x_max]\n",
        "                resized_img = cv2.resize(cropped_img, target_size)\n",
        "\n",
        "                output_img_path = os.path.join(\n",
        "                    class_dir, f\"{os.path.splitext(img_file)[0]}_{x_min}_{y_min}.jpg\"\n",
        "                )\n",
        "                cv2.imwrite(output_img_path, resized_img)\n"
      ],
      "metadata": {
        "id": "sWlKK62XNWI_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train set conversion\n",
        "images_dir = \"/content/dataset/train/images\"\n",
        "labels_dir = \"/content/dataset/train/labels\"\n",
        "output_dir = \"/content/train\"\n",
        "\n",
        "convert_dataset(images_dir, labels_dir, output_dir, class_names, target_size=(255, 255))"
      ],
      "metadata": {
        "id": "BS2d6ESrNaIZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#validation set conversion\n",
        "images_dir = \"/content/dataset/valid/images\"\n",
        "labels_dir = \"/content/dataset/valid/labels\"\n",
        "output_dir = \"/content/valid\"\n",
        "\n",
        "convert_dataset(images_dir, labels_dir, output_dir, class_names, target_size=(255, 255))"
      ],
      "metadata": {
        "id": "xhVBf213NcUb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test set conversion\n",
        "images_dir = \"/content/dataset/test/images\"\n",
        "labels_dir = \"/content/dataset/test/labels\"\n",
        "output_dir = \"/content/test\"\n",
        "\n",
        "convert_dataset(images_dir, labels_dir, output_dir, class_names, target_size=(255, 255))"
      ],
      "metadata": {
        "id": "OKOmSDgKQX5x"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!zip -r test_dataset_CNN.zip test/\n",
        "#from google.colab import files\n",
        "#files.download('test_dataset_CNN.zip')"
      ],
      "metadata": {
        "id": "iLfrlRXNQXkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/train'\n",
        "val_dir = '/content/valid'"
      ],
      "metadata": {
        "id": "jp2c9HKXSRBz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Augmentation and Preprocessing\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "#train and validation generators\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(255, 255),\n",
        "    batch_size=32,\n",
        "    class_mode='sparse'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(255, 255),\n",
        "    batch_size=32,\n",
        "    class_mode='sparse'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSI0BnCASeNw",
        "outputId": "09a9439b-21b6-4d22-b85c-4cb2182c40f0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 18111 images belonging to 106 classes.\n",
            "Found 1566 images belonging to 106 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate Class Weights\n",
        "#Use the training generator to get the labels\n",
        "training_labels = train_generator.classes\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(training_labels),\n",
        "    y=training_labels\n",
        ")\n",
        "class_weights = dict(enumerate(class_weights))"
      ],
      "metadata": {
        "id": "njDo3M4hDf-0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Custom CNN Model"
      ],
      "metadata": {
        "id": "-HRJMAtND-Dt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Custom CNN model\n",
        "model = models.Sequential()\n",
        "\n",
        "#convolutional and pooling layers with L2 regularization\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001), input_shape=(255, 255, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Flatten and Dense layers\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(layers.Dropout(0.3))  # Dropout to prevent overfitting\n",
        "model.add(layers.Dense(106, activation='softmax'))  # Output layer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvrzegQWSmOz",
        "outputId": "4a41a514-9f12-4a49-b445-baf7c2b54127"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=1e-4),\n",
        "    loss='sparse_categorical_crossentropy',  # For integer-encoded labels\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "fYGd47_hEJjl"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EarlyStopping to stop training if validation accuracy doesn't improve\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,  # Number of epochs with no improvement\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Learning rate reduction on plateau to reduce learning rate if no improvement\n",
        "lr_reduction = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    factor=0.1,\n",
        "    min_lr=1e-6\n",
        ")"
      ],
      "metadata": {
        "id": "dO9shUuJXdVB"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Training with Class Weights and Callbacks\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    epochs=30,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=val_generator.samples // val_generator.batch_size,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[early_stopping, lr_reduction],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiL9YznzEZg0",
        "outputId": "7fad614d-6456-4329-f13e-66756564f8f9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 515ms/step - accuracy: 0.0757 - loss: 4.7348 - val_accuracy: 0.4512 - val_loss: 2.6194 - learning_rate: 1.0000e-04\n",
            "Epoch 2/30\n",
            "\u001b[1m  1/565\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 71ms/step - accuracy: 0.3438 - loss: 3.6621"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3438 - loss: 3.6621 - val_accuracy: 0.4000 - val_loss: 2.6148 - learning_rate: 1.0000e-04\n",
            "Epoch 3/30\n",
            "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 488ms/step - accuracy: 0.3106 - loss: 3.0848 - val_accuracy: 0.6400 - val_loss: 1.9447 - learning_rate: 1.0000e-04\n",
            "Epoch 4/30\n",
            "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5000 - loss: 2.6027 - val_accuracy: 0.5667 - val_loss: 2.1315 - learning_rate: 1.0000e-04\n",
            "Epoch 5/30\n",
            "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 488ms/step - accuracy: 0.4190 - loss: 2.6166 - val_accuracy: 0.6940 - val_loss: 1.6592 - learning_rate: 1.0000e-04\n",
            "Epoch 6/30\n",
            "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65us/step - accuracy: 0.4375 - loss: 2.8713 - val_accuracy: 0.6000 - val_loss: 1.9899 - learning_rate: 1.0000e-04\n",
            "Epoch 7/30\n",
            "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 485ms/step - accuracy: 0.4837 - loss: 2.3747 - val_accuracy: 0.7552 - val_loss: 1.4459 - learning_rate: 1.0000e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.4375 - loss: 2.6984 - val_accuracy: 0.8000 - val_loss: 1.2874 - learning_rate: 1.0000e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 486ms/step - accuracy: 0.5299 - loss: 2.1989 - val_accuracy: 0.7793 - val_loss: 1.3569 - learning_rate: 1.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4688 - loss: 3.1870 - val_accuracy: 0.7667 - val_loss: 1.2759 - learning_rate: 1.0000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 483ms/step - accuracy: 0.5645 - loss: 2.0524 - val_accuracy: 0.8066 - val_loss: 1.2386 - learning_rate: 1.0000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5938 - loss: 1.9678 - val_accuracy: 0.8667 - val_loss: 1.1318 - learning_rate: 1.0000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 486ms/step - accuracy: 0.5970 - loss: 1.9513 - val_accuracy: 0.8320 - val_loss: 1.1147 - learning_rate: 1.0000e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - accuracy: 0.7188 - loss: 1.7797 - val_accuracy: 0.8667 - val_loss: 0.9786 - learning_rate: 1.0000e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 485ms/step - accuracy: 0.6236 - loss: 1.8719 - val_accuracy: 0.8568 - val_loss: 1.0654 - learning_rate: 1.0000e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.6562 - loss: 1.8188 - val_accuracy: 0.8667 - val_loss: 0.8939 - learning_rate: 1.0000e-04\n",
            "Epoch 17/30\n",
            "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 487ms/step - accuracy: 0.6336 - loss: 1.8033 - val_accuracy: 0.8568 - val_loss: 1.0546 - learning_rate: 1.0000e-04\n",
            "Epoch 18/30\n",
            "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7500 - loss: 1.6888 - val_accuracy: 0.9667 - val_loss: 0.8104 - learning_rate: 1.0000e-04\n",
            "Epoch 19/30\n",
            "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 485ms/step - accuracy: 0.6517 - loss: 1.7285 - val_accuracy: 0.8600 - val_loss: 1.0037 - learning_rate: 1.0000e-04\n",
            "Epoch 20/30\n",
            "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55us/step - accuracy: 0.6250 - loss: 2.6774 - val_accuracy: 0.8667 - val_loss: 0.9356 - learning_rate: 1.0000e-04\n",
            "Epoch 21/30\n",
            "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 488ms/step - accuracy: 0.6659 - loss: 1.6846 - val_accuracy: 0.8678 - val_loss: 0.9889 - learning_rate: 1.0000e-04\n",
            "Epoch 22/30\n",
            "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433us/step - accuracy: 0.5312 - loss: 2.4844 - val_accuracy: 0.7667 - val_loss: 1.0329 - learning_rate: 1.0000e-05\n",
            "Epoch 23/30\n",
            "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 487ms/step - accuracy: 0.7048 - loss: 1.5282 - val_accuracy: 0.8952 - val_loss: 0.8717 - learning_rate: 1.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "gcVNa7f_GABM",
        "outputId": "59dea86f-3e7e-416d-af79-54dad367f81d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m253\u001b[0m, \u001b[38;5;34m253\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m124\u001b[0m, \u001b[38;5;34m124\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m18,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m115200\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │      \u001b[38;5;34m58,982,912\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m106\u001b[0m)                 │          \u001b[38;5;34m54,378\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">253</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">253</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">124</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">124</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">115200</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │      <span style=\"color: #00af00; text-decoration-color: #00af00\">58,982,912</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">106</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">54,378</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m177,391,616\u001b[0m (676.70 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">177,391,616</span> (676.70 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m59,130,538\u001b[0m (225.57 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">59,130,538</span> (225.57 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m118,261,078\u001b[0m (451.13 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">118,261,078</span> (451.13 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import files\n",
        "\n",
        "#model.save('custom_cnn.h5')\n",
        "#files.download('custom_cnn.h5')"
      ],
      "metadata": {
        "id": "2OfobIpfGsZl"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training and Validation metrics"
      ],
      "metadata": {
        "id": "mTldI5d-EmAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model evaluation\n",
        "train_loss, train_accuracy = model.evaluate(train_generator)\n",
        "print(f\"Train Loss: {train_loss}\")\n",
        "print(f\"Train Accuracy: {train_accuracy}\")\n",
        "\n",
        "val_loss, val_accuracy = model.evaluate(val_generator)\n",
        "print(f\"Validation Loss: {val_loss}\")\n",
        "print(f\"Validation Accuracy: {val_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiZyWKhbVT81",
        "outputId": "6f4a0d67-f25f-441d-ad71-18f969f542d3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 487ms/step - accuracy: 0.7443 - loss: 1.4325\n",
            "Train Loss: 1.4262231588363647\n",
            "Train Accuracy: 0.7428082227706909\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step - accuracy: 0.8734 - loss: 1.0105\n",
            "Validation Loss: 1.0378884077072144\n",
            "Validation Accuracy: 0.85887610912323\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model evaluation on Test set"
      ],
      "metadata": {
        "id": "HEBr9xqdE4sc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dir = '/content/test'"
      ],
      "metadata": {
        "id": "XPxd7J5om3eC"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation for test set (only rescaling in this case)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Test data generator\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(255, 255),\n",
        "    batch_size=32,\n",
        "    class_mode='sparse',\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRDSSqL_mxSS",
        "outputId": "c9ec12df-2621-415e-cef7-f5ab1111e752"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 842 images belonging to 106 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikoel1Pwm7i1",
        "outputId": "293868c3-b4c4-4339-f54c-db3111cb7ba8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.7563 - loss: 1.4314\n",
            "Test Loss: 1.085860013961792\n",
            "Test Accuracy: 0.8521634340286255\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prediction on a sample from test set"
      ],
      "metadata": {
        "id": "x3RF8V_LFI3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = '/content/test/burger/augmented_video_11_shifting_mp4-6_jpg.rf.69232f921ae38c375ad0dee43bc30f02_237_270.jpg'\n",
        "#img_path = '/content/test/thank-you/augmented_video_4_darkness_mp4-6_jpg.rf.a4fd4af6858cdfd44c8058f797a1e014_276_246.jpg'\n",
        "\n",
        "img = image.load_img(img_path, target_size=(255, 255))\n",
        "img_array = image.img_to_array(img) / 255.0\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "actual_class_name = img_path.split('/')[-2]\n",
        "actual_class_index = test_generator.class_indices[actual_class_name]\n",
        "print(f\"Actual Class Index: {actual_class_index}\")\n",
        "print(f\"Actual Class Name: {actual_class_name}\")\n",
        "\n",
        "#prediction\n",
        "predictions = model.predict(img_array)\n",
        "predicted_class = np.argmax(predictions)\n",
        "print(f\"Predicted Class Index: {predicted_class}\")\n",
        "class_names = test_generator.class_indices\n",
        "class_names = {v: k for k, v in class_names.items()}\n",
        "print(f\"Predicted Class Name: {class_names[predicted_class]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUxqJs9Xo1x5",
        "outputId": "dedd3c56-157a-40c0-8efe-513fef482951"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual Class Index: 36\n",
            "Actual Class Name: burger\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Predicted Class Index: 36\n",
            "Predicted Class Name: burger\n"
          ]
        }
      ]
    }
  ]
}